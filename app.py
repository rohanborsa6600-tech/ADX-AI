import streamlit as st
import google.generativeai as genai
from pypdf import PdfReader
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.neighbors import NearestNeighbors
import os

# --- 1. рд╡реЗрдмрд╕рд╛рдИрдЯрдЪреЗ рд╕реЗрдЯрд┐рдВрдЧ ---
st.set_page_config(page_title="Smaran AI", page_icon="ЁЯдЦ")
st.title("ЁЯУЦ Smaran AI: Chat with PDF")

# --- 2. Sidebar рдордзреНрдпреЗ API Key рдШреЗрдгреЗ ---
with st.sidebar:
    st.header("Settings")
    api_key = st.text_input("Enter Google API Key:", type="password")
    st.info("рддреБрдордЪреА рдореЛрдлрдд API Key [рдпреЗрдереЗ рдорд┐рд│рд╡рд╛](https://aistudio.google.com/app/apikey)")

# --- 3. рдлрдВрдХреНрд╢рди: PDF рд╡рд╛рдЪрдгреЗ рдЖрдгрд┐ рдореЙрдбреЗрд▓ рдмрдирд╡рдгреЗ ---
@st.cache_resource
def load_data_and_model(pdf_file_path):
    # PDF рд╡рд╛рдЪрдгреЗ
    reader = PdfReader(pdf_file_path)
    text_chunks = []
    for i, page in enumerate(reader.pages):
        text = page.extract_text()
        if text:
            chunks = text.split('\n\n')
            for chunk in chunks:
                if len(chunk) > 30:
                    text_chunks.append(f"[Page {i+1}] {chunk}")
    
    # рд╕рд░реНрдЪ рдореЙрдбреЗрд▓ рдмрдирд╡рдгреЗ
    vectorizer = TfidfVectorizer(stop_words='english')
    X = vectorizer.fit_transform(text_chunks)
    nn = NearestNeighbors(n_neighbors=3, metric='cosine')
    nn.fit(X)
    
    return text_chunks, vectorizer, nn

# --- 4. рдореБрдЦреНрдп рдкреНрд░реЛрд╕реЗрд╕ ---
pdf_filename = "Smaranpath-DH.pdf"  # рддреБрдордЪреНрдпрд╛ PDF рдЪреЗ рдирд╛рд╡ рддрдВрддреЛрддрдВрдд рд╣реЗрдЪ рдЕрд╕рд╛рд╡реЗ

if not os.path.exists(pdf_filename):
    st.error(f"тЪая╕П '{pdf_filename}' рд╣реА рдлрд╛рдИрд▓ рд╕рд╛рдкрдбрд▓реА рдирд╛рд╣реА. рдХреГрдкрдпрд╛ GitHub рд╡рд░ рдЕрдкрд▓реЛрдб рдХрд░рд╛.")
else:
    # рдбреЗрдЯрд╛ рд▓реЛрдб рдХрд░рд╛
    corpus, vectorizer, nn = load_data_and_model(pdf_filename)

    # рдЪреЕрдЯ рдЗрдВрдЯрд░рдлреЗрд╕
    if "messages" not in st.session_state:
        st.session_state.messages = []

    # рдЬреБрдиреНрдпрд╛ рдЧрдкреНрдкрд╛ рджрд╛рдЦрд╡рд╛
    for message in st.session_state.messages:
        with st.chat_message(message["role"]):
            st.markdown(message["content"])

    # рдирд╡реАрди рдкреНрд░рд╢реНрди рд╡рд┐рдЪрд╛рд░рд╛
    if prompt := st.chat_input("рддреБрдордЪрд╛ рдкреНрд░рд╢реНрди рд╡рд┐рдЪрд╛рд░рд╛..."):
        if not api_key:
            st.warning("рдХреГрдкрдпрд╛ рдЖрдзреА Sidebar рдордзреНрдпреЗ API Key рдЯрд╛рдХрд╛!")
            st.stop()

        # рдпреБрдЬрд░рдЪрд╛ рдкреНрд░рд╢реНрди рджрд╛рдЦрд╡рд╛
        st.chat_message("user").markdown(prompt)
        st.session_state.messages.append({"role": "user", "content": prompt})

        # --- AI рдХрдбреВрди рдЙрддреНрддрд░ рдорд┐рд│рд╡рдгреЗ ---
        try:
            genai.configure(api_key=api_key)
            model = genai.GenerativeModel('gemini-1.5-flash')

            # рд╕рдВрджрд░реНрдн рд╢реЛрдзрдгреЗ
            q_vec = vectorizer.transform([prompt])
            distances, indices = nn.kneighbors(q_vec)
            context = "\n".join([corpus[i] for i in indices[0]])

            # AI рд▓рд╛ рдкреНрд░реЙрдореНрдкреНрдЯ
            full_prompt = f"""
            You are a helpful assistant. Use the context below to answer the question in Marathi.
            If the answer is not in the context, say "рдорд╛рд╣рд┐рддреА рдЙрдкрд▓рдмреНрдз рдирд╛рд╣реА".
            
            Context: {context}
            Question: {prompt}
            """
            
            response = model.generate_content(full_prompt)
            answer = response.text

            # рдЙрддреНрддрд░ рджрд╛рдЦрд╡рд╛
            with st.chat_message("assistant"):
                st.markdown(answer)
            st.session_state.messages.append({"role": "assistant", "content": answer})

        except Exception as e:
            st.error(f"Error: {e}")
